{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMRPr1iFaIynRMzpduKVISE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dansah2/Udacity_Tutorials/blob/main/Udacity_NLP_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "USJ0joiN89uo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data\n",
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWg44IDB9VBl",
        "outputId": "9cf9e1eb-7cf7-43d1-bcfc-e4239b98adbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-06 16:36:12--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.127.102, 108.177.127.138, 108.177.127.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.127.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0fpl67v353vi32tou3khhicl4739cmcv/1688661375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=f936b38d-d6c3-447c-82f0-6c62b9decfca [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-07-06 16:36:15--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0fpl67v353vi32tou3khhicl4739cmcv/1688661375000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=f936b38d-d6c3-447c-82f0-6c62b9decfca\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 108.177.126.132, 2a00:1450:4013:c01::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|108.177.126.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  55.6MB/s    in 1.2s    \n",
            "\n",
            "2023-07-06 16:36:17 (55.6 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create functions to tokenize the lyrics, remove punctuation and make everyting lowercase\n",
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # fit tokenizer to the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # remove punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "\n",
        "  # convert to lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "\n",
        "  # create one long string split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "\n",
        "  # remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "\n",
        "  # remove empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "metadata": {
        "id": "21hp0q4c9aJK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the first 10 songs from the dataset\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "\n",
        "# create the corpus using the 'text column containing the lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "\n",
        "# tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrP0M-fFAdrl",
        "outputId": "3d1458a5-5b75-4640-e2df-1463c53db4d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-22dd0975633a>:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-3-22dd0975633a>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-3-22dd0975633a>:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.lower()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequence = token_list[:i+1]\n",
        "    sequences.append(n_gram_sequence)\n",
        "\n",
        "# padd the sequences\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# split the sequences between the input sequence and the output prediction word\n",
        "input_sequences, labels = sequences[:, :-1], sequences[:,-1]\n",
        "\n",
        "# one hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "O2N-0d1vBUA-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check how the data is being stored\n",
        "# the Tokenizer has a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "\n",
        "# input sequences have multiple idexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "\n",
        "# and the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOyI7kVGC7kl",
        "outputId": "a0ac6aa1-843f-4a3f-b374-39ebe3e80647"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i33asItiDsOR",
        "outputId": "ae29c8d3-a9a1-4336-8303-7fa4215d6a6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 15s 90ms/step - loss: 6.0143 - accuracy: 0.0217\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 2s 40ms/step - loss: 5.4425 - accuracy: 0.0373\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 5.3675 - accuracy: 0.0399\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 5.3040 - accuracy: 0.0399\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 5.2298 - accuracy: 0.0399\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 2s 30ms/step - loss: 5.1629 - accuracy: 0.0399\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 5.0997 - accuracy: 0.0424\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 5.0268 - accuracy: 0.0449\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 4.9525 - accuracy: 0.0515\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.8667 - accuracy: 0.0636\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 4.7796 - accuracy: 0.0777\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 4.6897 - accuracy: 0.0832\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.6011 - accuracy: 0.0858\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 4.5152 - accuracy: 0.0938\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 4.4263 - accuracy: 0.0954\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.3473 - accuracy: 0.1090\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 4.2693 - accuracy: 0.1125\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.1948 - accuracy: 0.1241\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 4.1243 - accuracy: 0.1292\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 4.0670 - accuracy: 0.1413\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.0091 - accuracy: 0.1534\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.9396 - accuracy: 0.1700\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 3.9073 - accuracy: 0.1761\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.8415 - accuracy: 0.1892\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.7590 - accuracy: 0.2164\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.7094 - accuracy: 0.2361\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.6363 - accuracy: 0.2462\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.5787 - accuracy: 0.2598\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.5150 - accuracy: 0.2760\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.4563 - accuracy: 0.2886\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.4098 - accuracy: 0.3012\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.3496 - accuracy: 0.3093\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.2995 - accuracy: 0.3269\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 3.2445 - accuracy: 0.3239\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.1942 - accuracy: 0.3385\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.1426 - accuracy: 0.3451\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 3.1019 - accuracy: 0.3537\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0516 - accuracy: 0.3577\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.9939 - accuracy: 0.3693\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.9473 - accuracy: 0.3774\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.9093 - accuracy: 0.3764\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.8707 - accuracy: 0.3860\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.8272 - accuracy: 0.4021\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 2.7881 - accuracy: 0.4092\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.7448 - accuracy: 0.4122\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6981 - accuracy: 0.4324\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.6564 - accuracy: 0.4258\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6233 - accuracy: 0.4309\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 2.5757 - accuracy: 0.4410\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.5314 - accuracy: 0.4521\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.4887 - accuracy: 0.4667\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 2.4575 - accuracy: 0.4677\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 2.4154 - accuracy: 0.4692\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3976 - accuracy: 0.4707\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3602 - accuracy: 0.4859\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 2.3118 - accuracy: 0.4945\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 2.2693 - accuracy: 0.4965\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 2.2387 - accuracy: 0.5066\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 2.2068 - accuracy: 0.5182\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 1s 22ms/step - loss: 2.1653 - accuracy: 0.5232\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 2.1301 - accuracy: 0.5328\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 1s 18ms/step - loss: 2.1039 - accuracy: 0.5353\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.0759 - accuracy: 0.5394\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 2.0378 - accuracy: 0.5454\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.9909 - accuracy: 0.5651\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.9759 - accuracy: 0.5616\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.9496 - accuracy: 0.5691\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.9045 - accuracy: 0.5772\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.8817 - accuracy: 0.5858\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.8579 - accuracy: 0.5822\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 1.8188 - accuracy: 0.6004\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.7871 - accuracy: 0.6075\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.7654 - accuracy: 0.6095\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 1.7678 - accuracy: 0.6115\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.7464 - accuracy: 0.6080\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.7218 - accuracy: 0.6201\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.6965 - accuracy: 0.6256\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 1.6569 - accuracy: 0.6302\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.6338 - accuracy: 0.6377\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.6115 - accuracy: 0.6468\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.6018 - accuracy: 0.6433\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.5797 - accuracy: 0.6458\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.5477 - accuracy: 0.6549\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.5205 - accuracy: 0.6690\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 1.6124 - accuracy: 0.6312\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.5049 - accuracy: 0.6695\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.4736 - accuracy: 0.6660\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.4432 - accuracy: 0.6842\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 1s 24ms/step - loss: 1.4123 - accuracy: 0.6897\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.3948 - accuracy: 0.6922\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 1s 21ms/step - loss: 1.3655 - accuracy: 0.6958\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.3436 - accuracy: 0.7064\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 1.3270 - accuracy: 0.7109\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.3133 - accuracy: 0.7129\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.2951 - accuracy: 0.7139\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.2781 - accuracy: 0.7245\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.2582 - accuracy: 0.7275\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 1.2492 - accuracy: 0.7321\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 1s 19ms/step - loss: 1.2288 - accuracy: 0.7366\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.2179 - accuracy: 0.7311\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.2099 - accuracy: 0.7386\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.1947 - accuracy: 0.7371\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.1706 - accuracy: 0.7462\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.1549 - accuracy: 0.7477\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.1381 - accuracy: 0.7548\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.1286 - accuracy: 0.7487\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.1176 - accuracy: 0.7588\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.1095 - accuracy: 0.7644\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.0998 - accuracy: 0.7624\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.0947 - accuracy: 0.7629\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 1.0944 - accuracy: 0.7497\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 1.0627 - accuracy: 0.7629\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.0464 - accuracy: 0.7730\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.0278 - accuracy: 0.7704\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 1.0232 - accuracy: 0.7725\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.0096 - accuracy: 0.7780\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 0.9957 - accuracy: 0.7780\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 1s 17ms/step - loss: 0.9807 - accuracy: 0.7846\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 1s 23ms/step - loss: 0.9663 - accuracy: 0.7800\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.9558 - accuracy: 0.7841\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.9487 - accuracy: 0.7871\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.9350 - accuracy: 0.7921\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.9190 - accuracy: 0.7972\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.9074 - accuracy: 0.7972\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.9124 - accuracy: 0.7947\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8936 - accuracy: 0.7972\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.8934 - accuracy: 0.7977\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9146 - accuracy: 0.7921\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8958 - accuracy: 0.7906\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.9134 - accuracy: 0.7891\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8658 - accuracy: 0.8037\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8444 - accuracy: 0.8068\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8429 - accuracy: 0.8093\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8432 - accuracy: 0.8073\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8262 - accuracy: 0.8078\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8270 - accuracy: 0.8078\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.8186 - accuracy: 0.8174\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 2s 28ms/step - loss: 0.8178 - accuracy: 0.8103\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 0.7986 - accuracy: 0.8128\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7955 - accuracy: 0.8148\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7807 - accuracy: 0.8169\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7640 - accuracy: 0.8229\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.7541 - accuracy: 0.8239\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7433 - accuracy: 0.8274\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7393 - accuracy: 0.8300\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7314 - accuracy: 0.8264\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7237 - accuracy: 0.8310\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7164 - accuracy: 0.8325\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7120 - accuracy: 0.8325\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.7123 - accuracy: 0.8340\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.6973 - accuracy: 0.8391\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6815 - accuracy: 0.8436\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6769 - accuracy: 0.8446\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6708 - accuracy: 0.8461\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6886 - accuracy: 0.8340\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6770 - accuracy: 0.8360\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.6824 - accuracy: 0.8431\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.7092 - accuracy: 0.8234\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6981 - accuracy: 0.8330\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.6703 - accuracy: 0.8411\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 0.6717 - accuracy: 0.8406\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.6670 - accuracy: 0.8375\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6356 - accuracy: 0.8496\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6328 - accuracy: 0.8476\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6201 - accuracy: 0.8491\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6089 - accuracy: 0.8522\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5972 - accuracy: 0.8557\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5914 - accuracy: 0.8567\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5847 - accuracy: 0.8552\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5776 - accuracy: 0.8547\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5728 - accuracy: 0.8618\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5680 - accuracy: 0.8557\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5663 - accuracy: 0.8567\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5616 - accuracy: 0.8602\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5675 - accuracy: 0.8552\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5644 - accuracy: 0.8582\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.7009 - accuracy: 0.8108\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.6418 - accuracy: 0.8325\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.6078 - accuracy: 0.8446\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5741 - accuracy: 0.8542\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5527 - accuracy: 0.8547\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5472 - accuracy: 0.8532\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5511 - accuracy: 0.8547\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5372 - accuracy: 0.8613\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5404 - accuracy: 0.8567\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 0.5308 - accuracy: 0.8572\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5288 - accuracy: 0.8613\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5208 - accuracy: 0.8592\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5388 - accuracy: 0.8577\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5297 - accuracy: 0.8577\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.5562 - accuracy: 0.8456\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5221 - accuracy: 0.8648\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.8668\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.8673\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4921 - accuracy: 0.8633\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4867 - accuracy: 0.8749\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 0.4838 - accuracy: 0.8703\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4863 - accuracy: 0.8673\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4924 - accuracy: 0.8708\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.8754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# view the training graph\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "36QQ3czGE1P5",
        "outputId": "888efdc9-3441-46e4-eef2-5a2fe89f52aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"I'm feeling chills\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "  output_word = ''\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += ' ' + output_word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JN1CwUJFXTQ",
        "outputId": "9dfa71b1-4a40-41e1-9f46-246e608c33a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "I'm feeling chills me sing and you and i morning your house cause i found out that what could i found could sure me strong found give what could i am not believe what a dreams you boomaboomerang its good as new before my last its crazy last take bang bang a boomaboomerang is love good as new dimension my god its not realized its good ground ground look found bang bang only realized only realized its realized its a boomaboomerang good as new dimension my god its good face its realized its no ground one take bang give time found realized song\n"
          ]
        }
      ]
    }
  ]
}