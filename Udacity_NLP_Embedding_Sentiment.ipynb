{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOSOIreA/qp9gYQM2zi8IG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dansah2/Udacity_Tutorials/blob/main/Udacity_NLP_Embedding_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3WIJKYfFEb8e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract dataset\n",
        "!wget --no-check-certificate \\\n",
        "    -O /tmp/sentiment.csv https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbK_ZjmEE4El",
        "outputId": "28643991-f33f-41e6-ac5d-479a52b06d95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-23 20:35:21--  https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.141.139, 142.250.141.102, 142.250.141.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.141.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/j5hvf2aev0b0k363a84eejts9k5tjiss/1687552500000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=aede4b83-2757-415e-b0af-7d8598cc26ae [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-06-23 20:35:22--  https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/j5hvf2aev0b0k363a84eejts9k5tjiss/1687552500000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=aede4b83-2757-415e-b0af-7d8598cc26ae\n",
            "Resolving doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n",
            "Connecting to doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)|142.251.2.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 127831 (125K) [text/csv]\n",
            "Saving to: ‘/tmp/sentiment.csv’\n",
            "\n",
            "/tmp/sentiment.csv  100%[===================>] 124.83K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-06-23 20:35:22 (1.92 MB/s) - ‘/tmp/sentiment.csv’ saved [127831/127831]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# read the data into a dataframe\n",
        "dataset = pd.read_csv('/tmp/sentiment.csv')\n",
        "\n",
        "#define the sentences and the labels\n",
        "sentences = dataset['text'].tolist()\n",
        "labels = dataset['sentiment'].tolist()\n",
        "\n",
        "\n",
        "# seperate sentences/labels into training/test sets\n",
        "training_size = int(len(sentences) * 0.8)\n",
        "\n",
        "training_sentences = sentences[0:training_size]\n",
        "testing_sentences = sentences[training_size:]\n",
        "training_labels = labels[0:training_size]\n",
        "testing_labels = labels[training_size:]\n",
        "\n",
        "# convert testing labels into numpy array\n",
        "training_labels_final = np.array(training_labels)\n",
        "testing_labels_final = np.array(testing_labels)"
      ],
      "metadata": {
        "id": "1gw-R8-KGnx8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the data\n",
        "\n",
        "# set hyperprams\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "truc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok='<OOV>'\n",
        "\n",
        "#instantiate tokenizer\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "\n",
        "#fit the tokenizer on the training data\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "\n",
        "# create a word index\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# sequence the training data\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "\n",
        "# create padded training sequences\n",
        "padded = pad_sequences(sequences, maxlen=max_length,\n",
        "                       padding=padding_type, truncating=truc_type)\n",
        "\n",
        "# sequence the testing data\n",
        "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "\n",
        "# create padded testing sequences\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length,\n",
        "                               padding=padding_type, truncating=truc_type)"
      ],
      "metadata": {
        "id": "7YHQePGfKakH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the sequences to make sure all the code in the previous cell\n",
        "# correctly executed\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "  return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(decode_review(padded[1]))\n",
        "print(training_sentences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMqK-fJLMVto",
        "outputId": "8c367eee-1221-4faf-bcd8-148e82a1085b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good case excellent value ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
            "Good case Excellent value.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build sentiment network\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(6, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# look at a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjuiCn7wPm1k",
        "outputId": "9c668e5a-fb5f-4f43-e2f7-89e64b67e272"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           16000     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 9606      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,613\n",
            "Trainable params: 25,613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set epochs\n",
        "num_epochs = 10\n",
        "\n",
        "#fit the model\n",
        "model.fit(padded, training_labels_final,\n",
        "          epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_oNSaeqb0F0",
        "outputId": "6b1e9d7e-21d5-4fe3-b7c1-c00b97aa3add"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 3s 20ms/step - loss: 0.6936 - accuracy: 0.5085 - val_loss: 0.7112 - val_accuracy: 0.4110\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 1s 14ms/step - loss: 0.6879 - accuracy: 0.5223 - val_loss: 0.6959 - val_accuracy: 0.4211\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 0.6772 - accuracy: 0.5468 - val_loss: 0.6970 - val_accuracy: 0.4211\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.6523 - accuracy: 0.5863 - val_loss: 0.6824 - val_accuracy: 0.4887\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 0.6009 - accuracy: 0.7112 - val_loss: 0.6397 - val_accuracy: 0.6291\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.8757 - val_loss: 0.5445 - val_accuracy: 0.7368\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.9090 - val_loss: 0.5111 - val_accuracy: 0.7444\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.2601 - accuracy: 0.9372 - val_loss: 0.4877 - val_accuracy: 0.7619\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.2017 - accuracy: 0.9542 - val_loss: 0.4763 - val_accuracy: 0.7669\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 0.1586 - accuracy: 0.9655 - val_loss: 0.4786 - val_accuracy: 0.7719\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcf6c8a1c90>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the weights of the embedding layer\n",
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "weights.shape"
      ],
      "metadata": {
        "id": "GLV00h8vdVBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b64796d-9634-4782-fd7c-ba798fc076b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "# write embedding vectors and metadata\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + '\\n')\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + '\\n')\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "ERRwoiDT-i5T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the files\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N8OijDQt_vPt",
        "outputId": "e3e5dbf9-e69e-4b22-db0b-4723ea86208c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_31b7169b-8caf-4db8-9ff9-3b32f1c08314\", \"vecs.tsv\", 189725)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_731eadb5-ecd6-4b31-9a41-adf648c00b11\", \"meta.tsv\", 6617)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict sentiment using the model\n",
        "fake_reviews = [\n",
        "    'I love this phone', 'I hate spaghetti',\n",
        "    'Everything was cold',\n",
        "    'Everything was hot exactly as I wanted',\n",
        "    'Everything was green',\n",
        "    'the hose seated us immediately',\n",
        "    'they gave us free chocolate cake and did not charge us',\n",
        "    'not sure about the wilted flowers on the table',\n",
        "    'only works when I stand on tippy toes',\n",
        "    'does not work when I stand on my head',\n",
        "    'I hate the food here'\n",
        "]\n",
        "print(fake_reviews)\n",
        "\n",
        "# create sequences\n",
        "padding_type = 'post'\n",
        "sample_sequences = tokenizer.texts_to_sequences(fake_reviews)\n",
        "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)\n",
        "\n",
        "print('\\n Check out these reviews, they are completely real')\n",
        "\n",
        "classes = model.predict(fakes_padded)\n",
        "\n",
        "# the closer the class is to one the more positive the review predictions\n",
        "for x in range(len(fake_reviews)):\n",
        "  print(fake_reviews[x])\n",
        "  print(classes[x])\n",
        "  print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Emsj1joAACZK",
        "outputId": "a3b8b3ba-7f19-468d-daa6-7162a1284144"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I love this phone', 'I hate spaghetti', 'Everything was cold', 'Everything was hot exactly as I wanted', 'Everything was green', 'the hose seated us immediately', 'they gave us free chocolate cake and did not charge us', 'not sure about the wilted flowers on the table', 'only works when I stand on tippy toes', 'does not work when I stand on my head', 'I hate the food here']\n",
            "\n",
            " Check out these reviews, they are completely real\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "I love this phone\n",
            "[0.98650587]\n",
            "\n",
            "\n",
            "I hate spaghetti\n",
            "[0.09821965]\n",
            "\n",
            "\n",
            "Everything was cold\n",
            "[0.54673505]\n",
            "\n",
            "\n",
            "Everything was hot exactly as I wanted\n",
            "[0.5110122]\n",
            "\n",
            "\n",
            "Everything was green\n",
            "[0.54160285]\n",
            "\n",
            "\n",
            "the hose seated us immediately\n",
            "[0.7933802]\n",
            "\n",
            "\n",
            "they gave us free chocolate cake and did not charge us\n",
            "[0.6580141]\n",
            "\n",
            "\n",
            "not sure about the wilted flowers on the table\n",
            "[0.05286513]\n",
            "\n",
            "\n",
            "only works when I stand on tippy toes\n",
            "[0.91257036]\n",
            "\n",
            "\n",
            "does not work when I stand on my head\n",
            "[0.01860403]\n",
            "\n",
            "\n",
            "I hate the food here\n",
            "[0.31648389]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSPRBTx6C46_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}